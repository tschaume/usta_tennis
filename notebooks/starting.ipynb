{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to init players collections, go to\n",
    "# https://www.ustanorcal.com/ntrpSearch.asp and\n",
    "# get html tables from 'View Page Source'\n",
    "# for all areas, genders, and levels with\n",
    "# filenames \"../html/<area>_<gender>_<level>.txt\"\n",
    "import json, os, bs4, requests, time, glob\n",
    "from datetime import datetime\n",
    "from bson import json_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cutoff_date = datetime(2013, 1, 1)\n",
    "base_url = 'https://www.ustanorcal.com'\n",
    "player_matches_url = '/'.join([base_url, 'PlayerMatches.asp?id={}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_player_id(name):\n",
    "    last_name, first_name = (n.strip() for n in name.split(','))\n",
    "    for player in players:\n",
    "        if player['last_name'] == last_name and player['first_name'] == first_name:\n",
    "            return player['_id']\n",
    "    raise ValueError('{} not found!'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players, player_ids = [], []\n",
    "for filename in glob.iglob('../html/*.txt'):\n",
    "    fn = os.path.basename(filename)\n",
    "    area, gender, level = os.path.splitext(fn)[0].split('_')\n",
    "    print(area, gender, level)\n",
    "    with open(filename, 'r') as f:\n",
    "        soup = bs4.BeautifulSoup(f, 'html.parser')\n",
    "    for row in soup.table.children:\n",
    "        if isinstance(row, bs4.element.Tag):\n",
    "            if not row.td.text or row.td.text == 'Player' or 'Total' in row.td.text:\n",
    "                continue\n",
    "            columns = [col for col in row.children if isinstance(col, bs4.element.Tag)]\n",
    "            _id = int(columns[0].a['href'].split('=')[-1])\n",
    "            if _id in player_ids: continue\n",
    "            else: player_ids.append(_id)\n",
    "            try:\n",
    "                d = dict(\n",
    "                    _id = _id, city = columns[1].text,\n",
    "                    rating_level = float(columns[4].text[:3]),\n",
    "                    rating_type = columns[4].text[3:],\n",
    "                    age_group = columns[-1].text, gender = gender, area = area\n",
    "                )\n",
    "                name = columns[0].a.text.split(',')\n",
    "                d['first_name'] = name[-1].strip().split()[0]\n",
    "                d['last_name'] = name[0].strip()\n",
    "                players.append(d)\n",
    "            except:\n",
    "                print(row)\n",
    "                raise\n",
    "\n",
    "with open('../data/players.json', 'w') as players_file:\n",
    "    json.dump(players, players_file)\n",
    "print(len(players))\n",
    "print(players[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches, individual_match_ids = {}, []\n",
    "for player_idx, player in enumerate(players):\n",
    "    if player['_id'] != 169636: continue\n",
    "    #if player_idx > 5: break\n",
    "    response = requests.get(player_matches_url.format(player['_id']))\n",
    "    matches_html = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "    for league_idx, row_league in enumerate(matches_html.find(id='leagues_section').children):\n",
    "        if isinstance(row_league, bs4.element.Tag) and \\\n",
    "        row_league.td and row_league.td.a:\n",
    "            print(player_idx, player['last_name'], league_idx)\n",
    "            url = '/'.join([base_url, row_league.td.a['href']])\n",
    "            r = requests.get(url).content\n",
    "            season_matches_html = bs4.BeautifulSoup(r, 'html.parser')\n",
    "            for row in season_matches_html.find(\"table\", class_=\"table well\").children:\n",
    "                if isinstance(row, bs4.element.Tag) and row.td:\n",
    "                    columns = [col for col in row.children if isinstance(col, bs4.element.Tag)]\n",
    "                    match_id = int(columns[0].a['href'].split('?')[-1].split('&')[0].split('=')[1])\n",
    "                    line, match_type = columns[6].text.lower().split()\n",
    "                    individual_match_id = '_'.join([str(match_id), line + match_type[0]])\n",
    "                    if individual_match_id in individual_match_ids:\n",
    "                        continue\n",
    "                    else:\n",
    "                        individual_match_ids.append(individual_match_id)\n",
    "                    line_idx = int(line) - 1\n",
    "                    if match_id not in matches:\n",
    "                        match_date = datetime.strptime(columns[0].a.text, '%m/%d/%Y')\n",
    "                        if match_date < cutoff_date:\n",
    "                            continue\n",
    "                        matches[match_id] = dict(\n",
    "                            date = match_date,\n",
    "                            league = columns[1].a.text.split()[-1][:-1],\n",
    "                            singles = [None, None], doubles = [None, None, None]\n",
    "                        )\n",
    "                    matches[match_id][match_type][line_idx] = dict(\n",
    "                        score = columns[5].text.strip().split(','), # TODO save numerically?\n",
    "                    )\n",
    "                    home_players = [p.text for p in columns[2].find_all('a')]\n",
    "                    visiting_players = [p.text for p in columns[4].find_all('a')]\n",
    "                    winners = [p.text for p in columns[7].find_all('a')]\n",
    "                    losers = home_players if visiting_players == winner else visiting_players\n",
    "                    print(match_id)\n",
    "                    matches[match_id][match_type][line_idx].update(dict(\n",
    "                            winners = [get_player_id(name) for name in winners],\n",
    "                            losers = [get_player_id(name) for name in losers]\n",
    "                        ))\n",
    "            time.sleep(.5)\n",
    "\n",
    "matches_coll = []\n",
    "for match_id in list(matches.keys()):\n",
    "    match = matches.pop(match_id)\n",
    "    match['_id'] = match_id\n",
    "    matches_coll.append(match)\n",
    "\n",
    "with open('../data/matches.json', 'w') as matches_file:\n",
    "    json.dump(matches_coll, matches_file, default=json_util.default)\n",
    "print(len(matches_coll))\n",
    "if matches_coll:\n",
    "    print(matches_coll[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
